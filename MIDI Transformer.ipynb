{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from models.midi_transformer import MIDITransformer\n",
    "from models.helpers.blocks import TransformerXLEncoderStack, TransformerXLDecoderStack\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/home/richhiey/Desktop/workspace/projects/virtual_musicians\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, 'data', 'POP909-Dataset')\n",
    "MODEL_SAVE_PATH = os.path.join(BASE_DIR, 'checkpoints', 'model1')\n",
    "MODEL_CONFIG_PATH = os.path.join(BASE_DIR, 'model-store', 'models', 'configs', 'default.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformer = MIDITransformer(MODEL_CONFIG_PATH, MODEL_SAVE_PATH, dynamic=True)\n",
    "\n",
    "configs = {\n",
    "\t\"encoder\": {\n",
    "        \"num_layers\": \"4\",\n",
    "        \"d_model\": \"128\",\n",
    "        \"num_heads\": \"8\",\n",
    "        \"dff\": \"128\",\n",
    "        \"input_vocab_size\": \"256\",\n",
    "        \"maximum_position_encoding\": \"256\",\n",
    "        \"memory_length\": \"256\",\n",
    "        \"dropout_rate\": \"0.1\",\n",
    "        \"max_sequence_length\": \"256\"\n",
    "\t},\n",
    "\t\"decoder\": {\n",
    "        \"num_layers\": \"4\",\n",
    "        \"d_model\": \"128\",\n",
    "        \"num_heads\": \"8\",\n",
    "        \"dff\": \"128\",\n",
    "        \"target_vocab_size\": \"256\",\n",
    "        \"maximum_position_encoding\": \"128\",\n",
    "        \"memory_length\": \"256\",\n",
    "        \"dropout_rate\": \"0.1\",\n",
    "        \"max_sequence_length\": \"128\"\n",
    "\t}\n",
    "}\n",
    "\n",
    "encoder = TransformerXLEncoderStack(configs['encoder'], dynamic=True)\n",
    "decoder = TransformerXLDecoderStack(configs['decoder'], dynamic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 10 256 128], shape=(3,), dtype=int32)\n",
      "tf.Tensor([ 10 256 128], shape=(3,), dtype=int32)\n",
      "tf.Tensor([ 10 256 128], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "inputx = tf.random.uniform(shape=(10,256), maxval=128, dtype=tf.int32)\n",
    "pe = tf.random.uniform(shape=(512,128), dtype=tf.float32)\n",
    "look_ahead_mask = tf.sequence_mask([200], maxlen=256)\n",
    "look_ahead_mask = tf.tile(tf.expand_dims(look_ahead_mask, axis=1), [1, 10, 1])\n",
    "\n",
    "encoder_output = encoder([inputx, tf.constant(256)], pe)\n",
    "print(tf.shape(encoder_output))\n",
    "decoder_output, attn_weights = decoder([inputx, tf.constant(256)], encoder_output, pe, look_ahead_mask)\n",
    "print(tf.shape(decoder_output))\n",
    "print(tf.shape(attn_weights))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "model_store_venv",
   "language": "python",
   "name": "model_store_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
