{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External imports\n",
    "import os\n",
    "import pretty_midi\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#import note_seq\n",
    "#import IPython\n",
    "\n",
    "# Internal imports\n",
    "from data.helpers.midi import MidiEventProcessor\n",
    "from models.midi_transformer import MIDITransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required file paths and common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths for local computer\n",
    "# ------------------------------------------------------------------------------------\n",
    "#BASE_DIR = \"/home/richhiey/Desktop/workspace/projects/virtual_musicians\"\n",
    "#DATA_DIR = os.path.join(BASE_DIR, \"data\", \"POP909-Dataset\", \"POP909\")\n",
    "#MIDI_EVENTS_PATH = os.path.join(BASE_DIR, \"data\", \"preprocessed\",  \"pop909-event-token.npy\")\n",
    "#DATASET_PATH = os.path.join(BASE_DIR, \"data\", \"preprocessed\",  \"pop909.tfrecords\")\n",
    "#MODEL_SAVE_PATH = os.path.join(BASE_DIR, \"cache\", 'checkpoints', 'model3')\n",
    "#MODEL_CONFIG_PATH = os.path.join(BASE_DIR, 'model-store', 'models', 'configs', 'default.json')\n",
    "\n",
    "## File paths for GPU Container\n",
    "# ------------------------------------------------------------------------------------\n",
    "BASE_DIR          = \"/home/rithomas\"\n",
    "PROJECT_DIR       = os.path.join(BASE_DIR, \"project\")\n",
    "DATA_DIR          = os.path.join(BASE_DIR, \"data\", \"POP909-Dataset\", \"POP909\")\n",
    "MIDI_EVENTS_PATH  = os.path.join(BASE_DIR, \"data\", \"preprocessed\",  \"pop909-event-token.npy\")\n",
    "DATASET_PATH      = os.path.join(BASE_DIR, \"data\", \"preprocessed\",  \"pop909.tfrecords\")\n",
    "MODEL_SAVE_PATH   = os.path.join(BASE_DIR, \"cache\", 'checkpoints', 'test_model')\n",
    "MODEL_CONFIG_PATH = os.path.join(PROJECT_DIR, 'model-store', 'models', 'configs', 'default.json')\n",
    "\n",
    "# Common variables\n",
    "# ------------------------------------------------------------------------------------\n",
    "feature_description = {\n",
    "    'melody': tf.io.VarLenFeature(tf.int64),\n",
    "    'rhythm': tf.io.VarLenFeature(tf.int64),\n",
    "    'bridge': tf.io.VarLenFeature(tf.int64)\n",
    "}\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading POP909 MIDI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(909,)\n"
     ]
    }
   ],
   "source": [
    "pop909 = np.load(MIDI_EVENTS_PATH, allow_pickle=True)\n",
    "print(np.shape(pop909))\n",
    "\n",
    "melodies = [song['MELODY'] for song in pop909]\n",
    "rhythms = [song['PIANO'] for song in pop909]\n",
    "bridges = [song['BRIDGE'] for song in pop909]\n",
    "\n",
    "if not os.path.exists(DATASET_PATH):\n",
    "    with tf.io.TFRecordWriter(DATASET_PATH) as file_writer:\n",
    "        for melody, rhythm, bridge in zip(melodies, rhythms, bridges):\n",
    "            example = tf.train.Example(\n",
    "                features=tf.train.Features(\n",
    "                    feature={\n",
    "                        \"melody\": tf.train.Feature(int64_list=tf.train.Int64List(value=melody)),\n",
    "                        \"rhythm\": tf.train.Feature(int64_list=tf.train.Int64List(value=rhythm)),\n",
    "                        \"bridge\": tf.train.Feature(int64_list=tf.train.Int64List(value=bridge))\n",
    "                    }\n",
    "                )\n",
    "            )\n",
    "            file_writer.write(example.SerializeToString())\n",
    "        file_writer.close()\n",
    "\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset(DATASET_PATH)\n",
    "dataset = raw_dataset.map(_parse_function).batch(BATCH_SIZE, drop_remainder=True).repeat(1000)\n",
    "event_processor = MidiEventProcessor()\n",
    "piano = pretty_midi.instrument_name_to_program('Acoustic Grand Piano')\n",
    "\n",
    "# Reconstruct MIDI data from TFRecord\n",
    "#for i, data in enumerate(dataset.take(3)):\n",
    "#    print('----------------------------------------------------------')\n",
    "#    full_midi = pretty_midi.PrettyMIDI()\n",
    "    \n",
    "#    melody_instr = pretty_midi.Instrument(program=piano)\n",
    "#    rhythm_instr = pretty_midi.Instrument(program=piano)\n",
    "#    bridge_instr = pretty_midi.Instrument(program=piano)\n",
    "    \n",
    "#    print('Melody:')\n",
    "#    melody_events = tf.sparse.to_dense(data['melody']).numpy()\n",
    "#    print(melody_events)\n",
    "#    for note in event_processor.decode(melody_events):\n",
    "#        melody_instr.notes.append(note)\n",
    "    \n",
    "#    print('Rhythm:')\n",
    "#    rhythm_events = tf.sparse.to_dense(data['rhythm']).numpy()\n",
    "#    print(rhythm_events)\n",
    "#    for note in event_processor.decode(rhythm_events):\n",
    "#        rhythm_instr.notes.append(note)\n",
    "    \n",
    "#    print('Bridge:')\n",
    "#    bridge_events = tf.sparse.to_dense(data['bridge']).numpy()\n",
    "#    print(bridge_events)\n",
    "#    for note in event_processor.decode(bridge_events):\n",
    "#        bridge_instr.notes.append(note)\n",
    "    \n",
    "#    full_midi.instruments.append(melody_instr)\n",
    "#    full_midi.instruments.append(rhythm_instr)\n",
    "#    full_midi.instruments.append(bridge_instr)\n",
    "#    IPython.display.display(IPython.display.Audio(full_midi.fluidsynth(), rate=44100))\n",
    "#    filename = 'test_'+str(i)+'.mid'\n",
    "#    full_midi.write(filename)\n",
    "    \n",
    "#    full_midi_ns = note_seq.midi_io.midi_file_to_note_sequence(filename)\n",
    "#    note_seq.plot_sequence(full_midi_ns)\n",
    "#    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transformer XL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DECODER from scratch.\n",
      "<models.midi_transformer.MIDITransformer object at 0x7f0e4038a6d8>\n",
      "<RepeatDataset shapes: {bridge: (32, None), melody: (32, None), rhythm: (32, None)}, types: {bridge: tf.int64, melody: tf.int64, rhythm: tf.int64}>\n",
      "Training the encoder on key: melody\n",
      "Training the encoder on key: melody\n",
      "WARNING:tensorflow:From /home/rithomas/project/venvs/ai_music_venv/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1203: start (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.start` instead.\n",
      "WARNING:tensorflow:From /home/rithomas/project/model-store/models/helpers/layers.py:80: calling Layer.add_update (from tensorflow.python.keras.engine.base_layer) with inputs is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`inputs` is now automatically inferred\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_1/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_2/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_3/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_4/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_5/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_6/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_7/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_8/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_9/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_10/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_1/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_2/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_3/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_4/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_5/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_6/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_7/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_8/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_9/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_10/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "WARNING:tensorflow:From /home/rithomas/project/venvs/ai_music_venv/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1259: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:From /home/rithomas/project/venvs/ai_music_venv/lib/python3.6/site-packages/tensorflow/python/ops/summary_ops_v2.py:1259: save (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "WARNING:tensorflow:From /home/rithomas/project/venvs/ai_music_venv/lib/python3.6/site-packages/tensorflow/python/eager/profiler.py:151: maybe_create_event_file (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "`tf.python.eager.profiler` has deprecated, use `tf.profiler` instead.\n",
      "Loss (0) - tf.Tensor(5.0847, shape=(), dtype=float32)\n",
      "Lets listen to what to the model sounds like step 0!\n",
      "tf.Tensor(\n",
      "[[[-1.017003    1.3719178   0.13336368 ...  0.8629969   1.453289\n",
      "    0.5956455 ]\n",
      "  [-1.0170008   1.3719438   0.1334101  ...  0.8629985   1.4531742\n",
      "    0.5956623 ]\n",
      "  [-1.0169665   1.3719572   0.13348871 ...  0.86294895  1.4531116\n",
      "    0.59569925]\n",
      "  ...\n",
      "  [-1.017158    1.3717608   0.13350731 ...  0.86305654  1.4529574\n",
      "    0.5956446 ]\n",
      "  [-1.0170381   1.3717493   0.13354188 ...  0.8629732   1.4530233\n",
      "    0.59560126]\n",
      "  [-1.0169272   1.3717325   0.1335715  ...  0.8628868   1.4531136\n",
      "    0.595555  ]]\n",
      "\n",
      " [[-1.0189183   1.3601727   0.12596351 ...  0.90683573  1.4308541\n",
      "    0.5965808 ]\n",
      "  [-1.0189006   1.3602188   0.12602404 ...  0.9068182   1.430754\n",
      "    0.5966042 ]\n",
      "  [-1.0188684   1.3602325   0.12608646 ...  0.9067734   1.4306844\n",
      "    0.59665304]\n",
      "  ...\n",
      "  [-1.0190058   1.3599466   0.12618145 ...  0.90682274  1.4305727\n",
      "    0.59669274]\n",
      "  [-1.0189029   1.3599203   0.12620975 ...  0.9067555   1.4306395\n",
      "    0.59667206]\n",
      "  [-1.018811    1.3598887   0.12624256 ...  0.90668476  1.430719\n",
      "    0.5966336 ]]\n",
      "\n",
      " [[-1.0148922   1.3575087   0.12233077 ...  0.9077567   1.4289786\n",
      "    0.5952402 ]\n",
      "  [-1.0148672   1.3575579   0.12238353 ...  0.90773976  1.4288741\n",
      "    0.5952601 ]\n",
      "  [-1.0148327   1.357573    0.12243831 ...  0.90769607  1.4288014\n",
      "    0.5953085 ]\n",
      "  ...\n",
      "  [-1.0149901   1.3573016   0.12252016 ...  0.9077407   1.4286932\n",
      "    0.5953507 ]\n",
      "  [-1.0148901   1.357275    0.12254796 ...  0.90767646  1.4287612\n",
      "    0.5953335 ]\n",
      "  [-1.0148016   1.3572412   0.12258318 ...  0.9076099   1.4288433\n",
      "    0.5952964 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.0183244   1.3868374   0.14300245 ...  0.8637607   1.460471\n",
      "    0.5963054 ]\n",
      "  [-1.018329    1.3868613   0.14304651 ...  0.8637605   1.4603695\n",
      "    0.59631616]\n",
      "  [-1.0182976   1.3868716   0.14312284 ...  0.863717    1.460313\n",
      "    0.59635377]\n",
      "  ...\n",
      "  [-1.0185384   1.3866606   0.14315122 ...  0.86381686  1.4601387\n",
      "    0.59631073]\n",
      "  [-1.0184155   1.3866487   0.14318049 ...  0.86373115  1.4602065\n",
      "    0.5962606 ]\n",
      "  [-1.0183015   1.3866334   0.14320923 ...  0.863643    1.4602964\n",
      "    0.5962115 ]]\n",
      "\n",
      " [[-1.008381    1.369996    0.12641443 ...  0.8851903   1.4521605\n",
      "    0.59391665]\n",
      "  [-1.0083753   1.3700181   0.12646168 ...  0.8851973   1.4520686\n",
      "    0.593936  ]\n",
      "  [-1.0083525   1.3700188   0.1265193  ...  0.88516533  1.4520077\n",
      "    0.59398556]\n",
      "  ...\n",
      "  [-1.0085218   1.3697239   0.12658378 ...  0.88519824  1.4518625\n",
      "    0.59407645]\n",
      "  [-1.0084088   1.3697058   0.12661347 ...  0.88512444  1.4519247\n",
      "    0.59403545]\n",
      "  [-1.0083055   1.3696859   0.12664193 ...  0.88505244  1.4520057\n",
      "    0.59398437]]\n",
      "\n",
      " [[-1.0217125   1.3630313   0.12452213 ...  0.9046237   1.4223301\n",
      "    0.5930462 ]\n",
      "  [-1.0217046   1.3630555   0.12459314 ...  0.9045987   1.4222304\n",
      "    0.5930636 ]\n",
      "  [-1.0216733   1.3630583   0.12466308 ...  0.9045443   1.4221653\n",
      "    0.5931022 ]\n",
      "  ...\n",
      "  [-1.0217797   1.3628216   0.12473029 ...  0.90462893  1.4220674\n",
      "    0.59315985]\n",
      "  [-1.021677    1.3628067   0.1247616  ...  0.9045509   1.4221413\n",
      "    0.5931334 ]\n",
      "  [-1.0215877   1.3627876   0.12479238 ...  0.9044673   1.4222276\n",
      "    0.59309274]]], shape=(32, 255, 256), dtype=float32)\n",
      "Saved checkpoint for step 1: /home/rithomas/cache/checkpoints/test_model/ckpt/decoder/ckpt-1\n",
      "Loss (1) - tf.Tensor(5.0803657, shape=(), dtype=float32)\n",
      "Loss (2) - tf.Tensor(5.0929966, shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_1/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_2/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_3/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_4/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_5/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_6/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_7/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_8/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Loss (3) - tf.Tensor(5.099309, shape=(), dtype=float32)\n",
      "Loss (4) - tf.Tensor(5.120839, shape=(), dtype=float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss (5) - tf.Tensor(5.07005, shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_1/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_2/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_3/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_4/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_5/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_6/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_7/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_8/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_9/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Loss (6) - tf.Tensor(5.082998, shape=(), dtype=float32)\n",
      "Loss (7) - tf.Tensor(5.079471, shape=(), dtype=float32)\n",
      "Loss (8) - tf.Tensor(5.0739036, shape=(), dtype=float32)\n",
      "Loss (9) - tf.Tensor(5.0635953, shape=(), dtype=float32)\n",
      "Loss (10) - tf.Tensor(5.0940976, shape=(), dtype=float32)\n",
      "Loss (11) - tf.Tensor(5.0759816, shape=(), dtype=float32)\n",
      "Loss (12) - tf.Tensor(5.0802956, shape=(), dtype=float32)\n",
      "Loss (13) - tf.Tensor(5.1014104, shape=(), dtype=float32)\n",
      "Loss (14) - tf.Tensor(5.0771275, shape=(), dtype=float32)\n",
      "Loss (15) - tf.Tensor(5.1356907, shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_1/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_2/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_3/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_4/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_5/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_6/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_7/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_8/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_9/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_10/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_11/weighted_loss/value:0\", shape=(), dtype=float32)\n",
      "Tensor(\"sparse_categorical_crossentropy_12/weighted_loss/value:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "midi_transformer = MIDITransformer(MODEL_CONFIG_PATH, MODEL_SAVE_PATH)\n",
    "midi_transformer.reset_states()\n",
    "print(midi_transformer)\n",
    "print(dataset)\n",
    "midi_transformer.train(dataset, {'inputs': 'melody', 'outputs': 'melody', 'num_epochs': '1000'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new Note Sequences with the MIDI Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#midi_transformer.predict(midi_note_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_music_env",
   "language": "python",
   "name": "ai_music_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
