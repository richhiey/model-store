{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from models.midi_transformer import MIDITransformer\n",
    "from models.helpers.blocks import TransformerXLEncoderStack, TransformerXLDecoderStack\n",
    "from models.helpers.utils import positional_encoding\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required file paths and common variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_DIR = \"/home/richhiey/Desktop/workspace/projects/virtual_musicians\"\n",
    "\n",
    "BASE_DIR = \"/home/rithomas\"\n",
    "DATA_DIR = os.path.join(BASE_DIR, \"data\", \"POP909-Dataset\", \"POP909\")\n",
    "DATASET_PATH = os.path.join(BASE_DIR, \"cache\", \"preprocessed\", \"POP909\", \"pop909-event-token.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading POP909 MIDI Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop909 = np.load(DATASET_PATH, allow_pickle=True)\n",
    "#dataset = tf.data.Dataset.from_tensor_slices(pop909)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Transformer XL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Encoder from scratch.\n",
      "Initializing Decoder from scratch.\n"
     ]
    }
   ],
   "source": [
    "MODEL_SAVE_PATH = os.path.join(BASE_DIR, \"cache\", 'checkpoints', 'model1')\n",
    "MODEL_CONFIG_PATH = os.path.join(BASE_DIR, 'project', 'model-store', 'models', 'configs', 'default.json')\n",
    "midi_transformer = MIDITransformer(MODEL_CONFIG_PATH, MODEL_SAVE_PATH)\n",
    "midi_transformer.reset_states()\n",
    "#midi_transformer.train(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create new Note Sequences with the MIDI Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#midi_transformer.predict(midi_note_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_music_env",
   "language": "python",
   "name": "ai_music_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
