{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(8, 256)]                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (8, 256, 128)             49792     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (8, 256, 512)             1312768   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (8, 256, 512)             2099200   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (8, 256, 64)              32832     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (8, 256, 389)             25285     \n",
      "=================================================================\n",
      "Total params: 3,519,877\n",
      "Trainable params: 3,519,877\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Restored from /home/richhiey/Desktop/workspace/projects/virtual_musicians/cache/test_model2/ckpt/ckpt-415\n"
     ]
    }
   ],
   "source": [
    "from models.composer.generate import Generator\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.ops import array_ops\n",
    "\n",
    "configs = {\n",
    "    'model_path': '/home/richhiey/Desktop/workspace/projects/virtual_musicians/cache/test_model2',\n",
    "    'vocab_size': 389,\n",
    "    'emb_size': 128,\n",
    "    'lstm_units': 512,\n",
    "    'dense_units': 64,\n",
    "    'max_timesteps': 256\n",
    "}\n",
    "\n",
    "g = Generator(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n",
      "tf.Tensor([[355 355 355 ...  73 291 201]], shape=(1, 2221), dtype=int64)\n",
      "[[355 355 355 ...  73 291 201]]\n",
      "<_GroupByWindowDataset shapes: (None, 1, None), types: tf.int64>\n",
      "tf.Tensor(\n",
      "[[[355 355 355 ...   0   0   0]]\n",
      "\n",
      " [[355 355 355 ...   0   0   0]]\n",
      "\n",
      " [[355 355 355 ...   0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[355 355 355 ...   0   0   0]]\n",
      "\n",
      " [[355 355 355 ...   0   0   0]]\n",
      "\n",
      " [[355 355 355 ...   0   0   0]]], shape=(8, 1, 1514), dtype=int64)\n",
      "tf.Tensor([   8    1 1514], shape=(3,), dtype=int32)\n",
      "Loss: 5.908307\n",
      "Saved checkpoint for step 421: /home/richhiey/Desktop/workspace/projects/virtual_musicians/cache/test_model2/ckpt/ckpt-416\n",
      "tf.Tensor([   8    1 1388], shape=(3,), dtype=int32)\n",
      "Loss: 5.893285\n",
      "Saved checkpoint for step 422: /home/richhiey/Desktop/workspace/projects/virtual_musicians/cache/test_model2/ckpt/ckpt-417\n",
      "tf.Tensor([   8    1 1787], shape=(3,), dtype=int32)\n",
      "Loss: 5.9142327\n",
      "Saved checkpoint for step 423: /home/richhiey/Desktop/workspace/projects/virtual_musicians/cache/test_model2/ckpt/ckpt-418\n",
      "tf.Tensor([   8    1 1274], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = '/home/richhiey/Desktop/workspace/projects/virtual_musicians/data-store/POP909-Dataset/data_process/pop909-event-token.npy'\n",
    "data = np.load(DATA_PATH, allow_pickle=True)\n",
    "print(len(data))\n",
    "melodies = [d['MELODY'] for d in data]\n",
    "\n",
    "def generator_fn():\n",
    "    for melody in melodies:\n",
    "        yield tf.convert_to_tensor([melody])\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(generator_fn, tf.int64, tf.TensorShape([1, None]))\n",
    "\n",
    "for data in dataset:\n",
    "    x = data\n",
    "    print(x)\n",
    "    print(x.numpy())\n",
    "    break\n",
    "\n",
    "boundaries = [128 * (i+1) for i in range(20)]\n",
    "batch_sizes = [8] * (len(boundaries) + 1)\n",
    "\n",
    "def _element_length_fn(x, y=None):\n",
    "    return array_ops.shape(x)[1]\n",
    "\n",
    "dataset = dataset.apply(\n",
    "    tf.data.experimental.bucket_by_sequence_length(\n",
    "        _element_length_fn,\n",
    "        boundaries,\n",
    "        batch_sizes,\n",
    "        drop_remainder=True,\n",
    "        pad_to_bucket_boundary=False\n",
    "    )\n",
    ")\n",
    "\n",
    "print(dataset)\n",
    "for x in dataset:\n",
    "    print(x)\n",
    "    break\n",
    "    \n",
    "\n",
    "g.train(dataset, {'num_epochs':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
